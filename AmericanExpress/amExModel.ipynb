{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amExModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trailblazerakash/MachineLearning/blob/master/AmericanExpress/amExModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jabx5snYUv2q",
        "colab_type": "code",
        "outputId": "770dbf7c-ddf0-4880-ee41-fa5edf241331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acFO1uRCbH37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "\n",
        "\n",
        "#import mlcrate as mlc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import lightgbm as lgb\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict, Counter\n",
        "import pickle as pkl\n",
        "import seaborn as sns\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Dot, Reshape, Add, Subtract\n",
        "from keras import objectives\n",
        "from keras import backend as K\n",
        "from keras import regularizers \n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.layers import (Input, Lambda, Embedding, GaussianDropout, Reshape, CuDNNGRU,\n",
        "                          BatchNormalization, Dropout, Dense, PReLU, Layer,ReLU, LeakyReLU,GRU, Bidirectional)\n",
        "from keras.layers.merge import concatenate\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from keras import callbacks\n",
        "from keras.layers import (Input, Lambda, Embedding, GaussianDropout, Reshape, CuDNNGRU,\n",
        "                          BatchNormalization, Dropout, Dense, PReLU, Layer,ReLU, LeakyReLU,GRU, Bidirectional)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5x2YV4yU71D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "campaign_data= pd.read_csv('/content/drive/My Drive/amExprt/train/campaign_data.csv')\n",
        "coupon_item_mapping=pd.read_csv('/content/drive/My Drive/amExprt/train/coupon_item_mapping.csv')\n",
        "customer_demographics=pd.read_csv('/content/drive/My Drive/amExprt/train/customer_demographics.csv')\n",
        "customer_transaction_data=pd.read_csv('/content/drive/My Drive/amExprt/train/customer_transaction_data.csv')\n",
        "item_data=pd.read_csv('/content/drive/My Drive/amExprt/train/item_data.csv')\n",
        "train=pd.read_csv('/content/drive/My Drive/amExprt/train/train.csv')\n",
        "\n",
        "\n",
        "test=pd.read_csv('/content/drive/My Drive/amExprt/test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReP6LQfcbF-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([train, test], sort=False).reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfZlESOqbO6h",
        "colab_type": "code",
        "outputId": "9cb4d4da-4f96-4579-cdf1-00ce2ed78fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>campaign_id</th>\n",
              "      <th>coupon_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>redemption_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>1053</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>116</td>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>635</td>\n",
              "      <td>205</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>644</td>\n",
              "      <td>1050</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1017</td>\n",
              "      <td>1489</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  campaign_id  coupon_id  customer_id  redemption_status\n",
              "0   1           13         27         1053                0.0\n",
              "1   2           13        116           48                0.0\n",
              "2   6            9        635          205                0.0\n",
              "3   7           13        644         1050                0.0\n",
              "4   9            8       1017         1489                0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BajaMSriP-GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltr = len(train)\n",
        "data = data.merge(campaign_data, on='campaign_id')#  campaign_data\n",
        "data['start_date'] = pd.to_datetime(data['start_date'], dayfirst=True)\n",
        "data['end_date'] = pd.to_datetime(data['end_date'], dayfirst=True)\n",
        "data['campaign_type'] = pd.Series(data['campaign_type'].factorize()[0]).replace(-1, np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26HTmqB8QFur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "customer_demographics['no_of_children'] = customer_demographics['no_of_children'].replace('3+', 3).astype(float)\n",
        "customer_demographics['family_size'] = customer_demographics['family_size'].replace('5+', 3).astype(float)\n",
        "customer_demographics['marital_status'] = pd.Series(customer_demographics['marital_status'].factorize()[0]).replace(-1, np.nan)\n",
        "customer_demographics['age_range'] = pd.Series(customer_demographics['age_range'].factorize()[0]).replace(-1, np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtfKCZD0QY6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rented_mean = customer_demographics.groupby(\"customer_id\")['rented'].mean().to_dict()\n",
        "data['rented_mean'] = data['customer_id'].map(rented_mean)\n",
        "# income_bracket\n",
        "income_bracket_sum = customer_demographics.groupby(\"customer_id\")['income_bracket'].sum().to_dict()\n",
        "data['income_bracket_sum'] = data['customer_id'].map(income_bracket_sum)\n",
        "# age_range\n",
        "age_range_mean = customer_demographics.groupby(\"customer_id\")['age_range'].mean().to_dict()\n",
        "data['age_range_mean'] = data['customer_id'].map(age_range_mean)\n",
        "# family_size\n",
        "family_size_mean = customer_demographics.groupby(\"customer_id\")['family_size'].mean().to_dict()\n",
        "data['family_size_mean'] = data['customer_id'].map(family_size_mean)\n",
        "# no_of_children\n",
        "no_of_children_mean = customer_demographics.groupby(\"customer_id\")['no_of_children'].mean().to_dict()\n",
        "data['no_of_children_mean'] = data['customer_id'].map(no_of_children_mean)\n",
        "no_of_children_count = customer_demographics.groupby(\"customer_id\")['no_of_children'].count().to_dict()\n",
        "data['no_of_children_count'] = data['customer_id'].map(no_of_children_count)\n",
        "# marital_status\n",
        "marital_status_count = customer_demographics.groupby(\"customer_id\")['marital_status'].count().to_dict()\n",
        "data['marital_status_count'] = data['customer_id'].map(marital_status_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPLFu9pjQcsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "customer_transaction_data['date'] = pd.to_datetime(customer_transaction_data['date'])\n",
        "quantity_mean = customer_transaction_data.groupby(\"customer_id\")['quantity'].mean().to_dict()\n",
        "data['quantity_mean'] = data['customer_id'].map(quantity_mean)\n",
        "coupon_discount_mean = customer_transaction_data.groupby(\"customer_id\")['coupon_discount'].mean().to_dict()\n",
        "data['coupon_discount_mean'] = data['customer_id'].map(coupon_discount_mean)\n",
        "# other_discount\n",
        "other_discount_mean = customer_transaction_data.groupby(\"customer_id\")['other_discount'].mean().to_dict()\n",
        "data['other_discount_mean'] = data['customer_id'].map(other_discount_mean)\n",
        "# day\n",
        "customer_transaction_data['day'] = customer_transaction_data.date.dt.day\n",
        "date_day_mean = customer_transaction_data.groupby(\"customer_id\")['day'].mean().to_dict()\n",
        "data['date_day_mean'] = data['customer_id'].map(date_day_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Yl-5hCQhVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coupon_item_mapping = coupon_item_mapping.merge(item_data, how = 'left', on = 'item_id')\n",
        "coupon_item_mapping['brand_type'] = pd.Series(coupon_item_mapping['brand_type'].factorize()[0]).replace(-1, np.nan)\n",
        "coupon_item_mapping['category'] = pd.Series(coupon_item_mapping['category'].factorize()[0]).replace(-1, np.nan)\n",
        "\n",
        "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].mean().to_dict()\n",
        "data['category_mean'] = data['coupon_id'].map(category)\n",
        "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].count().to_dict()\n",
        "data['category_count'] = data['coupon_id'].map(category)\n",
        "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].nunique().to_dict()\n",
        "data['category_nunique'] = data['coupon_id'].map(category)\n",
        "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].max().to_dict()\n",
        "data['category_max'] = data['coupon_id'].map(category)\n",
        "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].min().to_dict()\n",
        "data['category_min'] = data['coupon_id'].map(category)\n",
        "\n",
        "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].mean().to_dict()\n",
        "data['brand_mean'] = data['coupon_id'].map(brand_mean)\n",
        "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].count().to_dict()\n",
        "data['brand_count'] = data['coupon_id'].map(brand_mean)\n",
        "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].min().to_dict()\n",
        "data['brand_min'] = data['coupon_id'].map(brand_mean)\n",
        "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].max().to_dict()\n",
        "data['brand_max'] = data['coupon_id'].map(brand_mean)\n",
        "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].nunique().to_dict()\n",
        "data['brand_nunique'] = data['coupon_id'].map(brand_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jUngtGTQ19D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].mean().to_dict()\n",
        "data['selling_price_mean'] = data['customer_id'].map(selling_price_mean)\n",
        "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].sum().to_dict()\n",
        "data['selling_price_sum'] = data['customer_id'].map(selling_price_mean)\n",
        "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].min().to_dict()\n",
        "data['selling_price_min'] = data['customer_id'].map(selling_price_mean)\n",
        "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].max().to_dict()\n",
        "data['selling_price_max'] = data['customer_id'].map(selling_price_mean)\n",
        "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].nunique().to_dict()\n",
        "data['selling_price_nunique'] = data['customer_id'].map(selling_price_mean)\n",
        "train_cols = [i for i in data.columns if i not in ['id','redemption_status','start_date','end_date']]\n",
        "train_cols = ['campaign_id','coupon_id','campaign_type','rented_mean','income_bracket_sum','age_range_mean','family_size_mean',\n",
        " 'no_of_children_mean',\n",
        " 'no_of_children_count',\n",
        " 'marital_status_count',\n",
        " 'quantity_mean',\n",
        " 'coupon_discount_mean',\n",
        " 'other_discount_mean',\n",
        " 'date_day_mean',\n",
        " 'category_mean',\n",
        " 'category_nunique',\n",
        " 'category_max',\n",
        " 'category_min',\n",
        " 'brand_mean',\n",
        " 'brand_max',\n",
        " 'brand_nunique',\n",
        " 'selling_price_mean',\n",
        " 'selling_price_min',\n",
        " 'selling_price_nunique']\n",
        "data[train_cols] = data[train_cols].fillna(0)\n",
        "train = data[data['redemption_status'].notnull()]\n",
        "test = data[data['redemption_status'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcQgJJN7Q-FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fallback_auc(y_true, y_pred):\n",
        "    try:\n",
        "        return roc_auc_score(y_true, y_pred)\n",
        "    except:\n",
        "        return 0.5\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1DCc28LCINC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def init_seeds(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "    # The below is necessary for starting Numpy generated random numbers\n",
        "    # in a well-defined initial state.\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # The below is necessary for starting core Python generated random numbers\n",
        "    # in a well-defined state.\n",
        "\n",
        "    rn.seed(seed)\n",
        "\n",
        "    # Force TensorFlow to use single thread.\n",
        "    # Multiple threads are a potential source of\n",
        "    # non-reproducible results.\n",
        "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
        "\n",
        "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "    from keras import backend as K\n",
        "\n",
        "    # The below tf.set_random_seed() will make random number generation\n",
        "    # in the TensorFlow backend have a well-defined initial state.\n",
        "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
        "\n",
        "    tf.set_random_seed(seed)\n",
        "\n",
        "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "    K.set_session(sess)\n",
        "    return sess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtgWoZwxCK8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46e04554-df2b-4933-b489-2bc90bb286fd"
      },
      "source": [
        "\n",
        "f_size  = [int(np.absolute(data[f]).max()) + 1 for f in train_cols]\n",
        "k_latent = 2\n",
        "embedding_reg = 0.0002\n",
        "kernel_reg = 0.1\n",
        "\n",
        "def get_embed(x_input, x_size, k_latent):\n",
        "    if x_size > 0: #category\n",
        "        embed = Embedding(x_size, k_latent, input_length=1, \n",
        "                          embeddings_regularizer=l2(embedding_reg))(x_input)\n",
        "        embed = Flatten()(embed)\n",
        "    else:\n",
        "        embed = Dense(k_latent, kernel_regularizer=l2(embedding_reg))(x_input)\n",
        "    return embed\n",
        "\n",
        "def build_model_1(X, f_size):\n",
        "    dim_input = len(f_size)\n",
        "    \n",
        "    input_x = [Input(shape=(1,)) for i in range(dim_input)] \n",
        "     \n",
        "    biases = [get_embed(x, size, 2) for (x, size) in zip(input_x, f_size)]\n",
        "    \n",
        "    factors = [get_embed(x, size, k_latent) for (x, size) in zip(input_x, f_size)]\n",
        "    \n",
        "    s = Add()(factors)\n",
        "    \n",
        "    diffs = [Subtract()([s, x]) for x in factors]\n",
        "    \n",
        "    dots = [Dot(axes=1)([d, x]) for d,x in zip(diffs, factors)]\n",
        "    \n",
        "    x = Concatenate()(biases + dots)\n",
        "    x = BatchNormalization()(x)\n",
        "    output = Dense(1, activation='sigmoid', kernel_regularizer=l2(kernel_reg))(x)\n",
        "    model = Model(inputs=input_x, outputs=[output])\n",
        "    opt = Adam(clipnorm=0.2, lr=0.0031)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[auc])\n",
        "    output_f = factors + biases\n",
        "    model_features = Model(inputs=input_x, outputs=output_f)\n",
        "    return model, model_features\n",
        "n_epochs = 100\n",
        "P = 10\n",
        "batch_size = 2**P\n",
        "print(batch_size)\n",
        "\n",
        "earlystopper = EarlyStopping(patience=0, verbose=1)\n",
        "kf = StratifiedKFold(n_splits=10, shuffle = True, random_state = 228)\n",
        "# kf = GroupKFold(5)\n",
        "\n",
        "score = []\n",
        "prediction = np.zeros(len(test))\n",
        "validate = np.zeros(len(train))\n",
        "\n",
        "test_ = [np.absolute(test[f].values) for f in train_cols]\n",
        "y_train = train.redemption_status.values\n",
        "w_train = (30 * (y_train > 0).astype('float32') + 1).ravel()\n",
        "\n",
        "def schedule(epoch, lr):\n",
        "    if epoch <= 10:\n",
        "        lr = 0.0031\n",
        "    if epoch > 10:\n",
        "        lr = lr * 0.8\n",
        "    return lr\n",
        "lr_s = callbacks.LearningRateScheduler(schedule, verbose=1)\n",
        "pred = pd.DataFrame()\n",
        "for i , (tdx, vdx) in enumerate(kf.split(train, train.redemption_status)):\n",
        "    try:\n",
        "        del sess\n",
        "    except:\n",
        "        pass\n",
        "    sess = init_seeds(i)\n",
        "        \n",
        "    print(f\"FOLD : {i}\")\n",
        "    X_train = [np.absolute(train[f].iloc[tdx].values) for f in train_cols]\n",
        "    X_test = [np.absolute(train[f].iloc[vdx].values) for f in train_cols]\n",
        "    model, model_features = build_model_1(X_train, f_size)\n",
        "    csv_logger = callbacks.CSVLogger(f'training_focal_loss{i}.log')\n",
        "    model.fit(X_train,  y_train[tdx], \n",
        "          epochs=n_epochs, batch_size=batch_size, verbose=2, shuffle=True, \n",
        "          validation_data=(X_test,  y_train[vdx]), \n",
        "          callbacks=[earlystopper, csv_logger],\n",
        "\n",
        "         )\n",
        "    \n",
        "    pred[str(i)] = model.predict(test_,verbose = False,batch_size=batch_size).reshape(-1)\n",
        "    validate[vdx] = model.predict(X_test).reshape(-1)\n",
        "    \n",
        "    print(roc_auc_score(y_train[vdx], validate[vdx]))\n",
        "    score.append(roc_auc_score(y_train[vdx], validate[vdx]))\n",
        "    model.save_weights(f\"model{i}.h5\")\n",
        "    del X_train, X_test,model, model_features\n",
        "    gc.collect()\n",
        "    \n",
        "print(score)\n",
        "print(f\"CV : {np.mean(score)}\")\n",
        "    \n",
        "    \n",
        "tmp = pred.copy()\n",
        "for col in tmp.columns:\n",
        "    tmp[col] = tmp[col].rank()\n",
        "    \n",
        "tmp = tmp.mean(axis = 1)\n",
        "tmp  =tmp / tmp.max()\n",
        "day = 4\n",
        "sub = 5\n",
        "name = f\"day_{day}_sub_{sub}\"\n",
        "tmp = dict(zip(test.id.values, tmp))\n",
        "answer1 = pd.DataFrame()\n",
        "answer1['id'] = test.id.values\n",
        "answer1['redemption_status'] = answer1['id'].map(tmp)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1024\n",
            "FOLD : 0\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 24s - loss: 0.4757 - auc: 0.7685 - val_loss: 0.2154 - val_auc: 0.8841\n",
            "Epoch 2/100\n",
            " - 2s - loss: 0.1767 - auc: 0.9048 - val_loss: 0.1338 - val_auc: 0.8971\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1287 - auc: 0.9345 - val_loss: 0.1115 - val_auc: 0.8879\n",
            "Epoch 4/100\n",
            " - 2s - loss: 0.1080 - auc: 0.9458 - val_loss: 0.0987 - val_auc: 0.9021\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0951 - auc: 0.9521 - val_loss: 0.0905 - val_auc: 0.8946\n",
            "Epoch 6/100\n",
            " - 2s - loss: 0.0864 - auc: 0.9599 - val_loss: 0.0845 - val_auc: 0.9081\n",
            "Epoch 7/100\n",
            " - 2s - loss: 0.0797 - auc: 0.9596 - val_loss: 0.0789 - val_auc: 0.9051\n",
            "Epoch 8/100\n",
            " - 2s - loss: 0.0744 - auc: 0.9657 - val_loss: 0.0748 - val_auc: 0.9127\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0705 - auc: 0.9642 - val_loss: 0.0717 - val_auc: 0.9183\n",
            "Epoch 10/100\n",
            " - 2s - loss: 0.0670 - auc: 0.9709 - val_loss: 0.0684 - val_auc: 0.9178\n",
            "Epoch 11/100\n",
            " - 2s - loss: 0.0641 - auc: 0.9677 - val_loss: 0.0674 - val_auc: 0.9048\n",
            "Epoch 12/100\n",
            " - 2s - loss: 0.0615 - auc: 0.9698 - val_loss: 0.0657 - val_auc: 0.9043\n",
            "Epoch 13/100\n",
            " - 2s - loss: 0.0594 - auc: 0.9701 - val_loss: 0.0630 - val_auc: 0.8942\n",
            "Epoch 14/100\n",
            " - 2s - loss: 0.0573 - auc: 0.9708 - val_loss: 0.0621 - val_auc: 0.9149\n",
            "Epoch 15/100\n",
            " - 2s - loss: 0.0557 - auc: 0.9726 - val_loss: 0.0603 - val_auc: 0.9011\n",
            "Epoch 16/100\n",
            " - 2s - loss: 0.0541 - auc: 0.9719 - val_loss: 0.0595 - val_auc: 0.8983\n",
            "Epoch 17/100\n",
            " - 2s - loss: 0.0526 - auc: 0.9727 - val_loss: 0.0583 - val_auc: 0.8974\n",
            "Epoch 18/100\n",
            " - 2s - loss: 0.0514 - auc: 0.9742 - val_loss: 0.0587 - val_auc: 0.8986\n",
            "Epoch 00018: early stopping\n",
            "0.9029980309542461\n",
            "FOLD : 1\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 24s - loss: 0.4876 - auc: 0.7634 - val_loss: 0.2323 - val_auc: 0.8767\n",
            "Epoch 2/100\n",
            " - 2s - loss: 0.1787 - auc: 0.9067 - val_loss: 0.1422 - val_auc: 0.8722\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1291 - auc: 0.9439 - val_loss: 0.1202 - val_auc: 0.8677\n",
            "Epoch 4/100\n",
            " - 2s - loss: 0.1077 - auc: 0.9511 - val_loss: 0.1028 - val_auc: 0.8967\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0945 - auc: 0.9527 - val_loss: 0.0948 - val_auc: 0.8800\n",
            "Epoch 6/100\n",
            " - 2s - loss: 0.0855 - auc: 0.9589 - val_loss: 0.0875 - val_auc: 0.8991\n",
            "Epoch 7/100\n",
            " - 2s - loss: 0.0788 - auc: 0.9619 - val_loss: 0.0812 - val_auc: 0.8972\n",
            "Epoch 8/100\n",
            " - 2s - loss: 0.0737 - auc: 0.9625 - val_loss: 0.0767 - val_auc: 0.8789\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0692 - auc: 0.9658 - val_loss: 0.0735 - val_auc: 0.8772\n",
            "Epoch 10/100\n",
            " - 3s - loss: 0.0657 - auc: 0.9678 - val_loss: 0.0710 - val_auc: 0.8941\n",
            "Epoch 11/100\n",
            " - 2s - loss: 0.0627 - auc: 0.9681 - val_loss: 0.0694 - val_auc: 0.8714\n",
            "Epoch 12/100\n",
            " - 2s - loss: 0.0603 - auc: 0.9658 - val_loss: 0.0680 - val_auc: 0.8750\n",
            "Epoch 13/100\n",
            " - 2s - loss: 0.0578 - auc: 0.9687 - val_loss: 0.0659 - val_auc: 0.8454\n",
            "Epoch 14/100\n",
            " - 2s - loss: 0.0561 - auc: 0.9715 - val_loss: 0.0647 - val_auc: 0.8764\n",
            "Epoch 15/100\n",
            " - 2s - loss: 0.0542 - auc: 0.9733 - val_loss: 0.0632 - val_auc: 0.8739\n",
            "Epoch 16/100\n",
            " - 2s - loss: 0.0526 - auc: 0.9704 - val_loss: 0.0612 - val_auc: 0.8754\n",
            "Epoch 17/100\n",
            " - 2s - loss: 0.0511 - auc: 0.9728 - val_loss: 0.0606 - val_auc: 0.8678\n",
            "Epoch 18/100\n",
            " - 2s - loss: 0.0499 - auc: 0.9742 - val_loss: 0.0591 - val_auc: 0.8634\n",
            "Epoch 19/100\n",
            " - 2s - loss: 0.0488 - auc: 0.9762 - val_loss: 0.0586 - val_auc: 0.8770\n",
            "Epoch 20/100\n",
            " - 2s - loss: 0.0474 - auc: 0.9742 - val_loss: 0.0577 - val_auc: 0.8621\n",
            "Epoch 21/100\n",
            " - 2s - loss: 0.0467 - auc: 0.9759 - val_loss: 0.0574 - val_auc: 0.8481\n",
            "Epoch 22/100\n",
            " - 2s - loss: 0.0455 - auc: 0.9765 - val_loss: 0.0566 - val_auc: 0.8615\n",
            "Epoch 23/100\n",
            " - 2s - loss: 0.0447 - auc: 0.9770 - val_loss: 0.0574 - val_auc: 0.8574\n",
            "Epoch 00023: early stopping\n",
            "0.8694854368246843\n",
            "FOLD : 2\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 25s - loss: 0.4759 - auc: 0.7800 - val_loss: 0.1940 - val_auc: 0.8595\n",
            "Epoch 2/100\n",
            " - 3s - loss: 0.1767 - auc: 0.9105 - val_loss: 0.1346 - val_auc: 0.9107\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1287 - auc: 0.9348 - val_loss: 0.1111 - val_auc: 0.8975\n",
            "Epoch 4/100\n",
            " - 2s - loss: 0.1079 - auc: 0.9460 - val_loss: 0.1000 - val_auc: 0.9087\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0954 - auc: 0.9490 - val_loss: 0.0903 - val_auc: 0.9122\n",
            "Epoch 6/100\n",
            " - 2s - loss: 0.0867 - auc: 0.9560 - val_loss: 0.0850 - val_auc: 0.8968\n",
            "Epoch 7/100\n",
            " - 2s - loss: 0.0803 - auc: 0.9566 - val_loss: 0.0811 - val_auc: 0.8939\n",
            "Epoch 8/100\n",
            " - 2s - loss: 0.0754 - auc: 0.9556 - val_loss: 0.0759 - val_auc: 0.9048\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0713 - auc: 0.9593 - val_loss: 0.0725 - val_auc: 0.9150\n",
            "Epoch 10/100\n",
            " - 3s - loss: 0.0680 - auc: 0.9612 - val_loss: 0.0695 - val_auc: 0.9137\n",
            "Epoch 11/100\n",
            " - 2s - loss: 0.0652 - auc: 0.9620 - val_loss: 0.0666 - val_auc: 0.9035\n",
            "Epoch 12/100\n",
            " - 2s - loss: 0.0627 - auc: 0.9662 - val_loss: 0.0649 - val_auc: 0.9160\n",
            "Epoch 13/100\n",
            " - 2s - loss: 0.0606 - auc: 0.9625 - val_loss: 0.0646 - val_auc: 0.9096\n",
            "Epoch 14/100\n",
            " - 2s - loss: 0.0587 - auc: 0.9683 - val_loss: 0.0619 - val_auc: 0.9080\n",
            "Epoch 15/100\n",
            " - 2s - loss: 0.0571 - auc: 0.9650 - val_loss: 0.0602 - val_auc: 0.9200\n",
            "Epoch 16/100\n",
            " - 2s - loss: 0.0556 - auc: 0.9685 - val_loss: 0.0588 - val_auc: 0.9207\n",
            "Epoch 17/100\n",
            " - 2s - loss: 0.0541 - auc: 0.9692 - val_loss: 0.0577 - val_auc: 0.9084\n",
            "Epoch 18/100\n",
            " - 2s - loss: 0.0529 - auc: 0.9687 - val_loss: 0.0566 - val_auc: 0.9260\n",
            "Epoch 19/100\n",
            " - 2s - loss: 0.0517 - auc: 0.9718 - val_loss: 0.0561 - val_auc: 0.9160\n",
            "Epoch 20/100\n",
            " - 2s - loss: 0.0506 - auc: 0.9729 - val_loss: 0.0554 - val_auc: 0.9135\n",
            "Epoch 21/100\n",
            " - 3s - loss: 0.0497 - auc: 0.9709 - val_loss: 0.0546 - val_auc: 0.9135\n",
            "Epoch 22/100\n",
            " - 2s - loss: 0.0487 - auc: 0.9732 - val_loss: 0.0542 - val_auc: 0.9090\n",
            "Epoch 23/100\n",
            " - 2s - loss: 0.0479 - auc: 0.9758 - val_loss: 0.0534 - val_auc: 0.9157\n",
            "Epoch 24/100\n",
            " - 2s - loss: 0.0472 - auc: 0.9747 - val_loss: 0.0529 - val_auc: 0.9137\n",
            "Epoch 25/100\n",
            " - 2s - loss: 0.0463 - auc: 0.9750 - val_loss: 0.0527 - val_auc: 0.9123\n",
            "Epoch 26/100\n",
            " - 2s - loss: 0.0456 - auc: 0.9764 - val_loss: 0.0518 - val_auc: 0.9103\n",
            "Epoch 27/100\n",
            " - 2s - loss: 0.0447 - auc: 0.9761 - val_loss: 0.0510 - val_auc: 0.9115\n",
            "Epoch 28/100\n",
            " - 2s - loss: 0.0443 - auc: 0.9765 - val_loss: 0.0513 - val_auc: 0.9085\n",
            "Epoch 00028: early stopping\n",
            "0.9226108558644392\n",
            "FOLD : 3\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 25s - loss: 0.4791 - auc: 0.7577 - val_loss: 0.2145 - val_auc: 0.8317\n",
            "Epoch 2/100\n",
            " - 2s - loss: 0.1767 - auc: 0.9086 - val_loss: 0.1415 - val_auc: 0.8511\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1284 - auc: 0.9336 - val_loss: 0.1167 - val_auc: 0.8608\n",
            "Epoch 4/100\n",
            " - 2s - loss: 0.1075 - auc: 0.9439 - val_loss: 0.1015 - val_auc: 0.8699\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0949 - auc: 0.9525 - val_loss: 0.0941 - val_auc: 0.8660\n",
            "Epoch 6/100\n",
            " - 2s - loss: 0.0860 - auc: 0.9557 - val_loss: 0.0900 - val_auc: 0.8710\n",
            "Epoch 7/100\n",
            " - 2s - loss: 0.0795 - auc: 0.9585 - val_loss: 0.0819 - val_auc: 0.8481\n",
            "Epoch 8/100\n",
            " - 2s - loss: 0.0745 - auc: 0.9619 - val_loss: 0.0792 - val_auc: 0.8750\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0704 - auc: 0.9629 - val_loss: 0.0751 - val_auc: 0.8452\n",
            "Epoch 10/100\n",
            " - 2s - loss: 0.0671 - auc: 0.9646 - val_loss: 0.0726 - val_auc: 0.8803\n",
            "Epoch 11/100\n",
            " - 2s - loss: 0.0643 - auc: 0.9666 - val_loss: 0.0705 - val_auc: 0.8646\n",
            "Epoch 12/100\n",
            " - 2s - loss: 0.0617 - auc: 0.9662 - val_loss: 0.0696 - val_auc: 0.8682\n",
            "Epoch 13/100\n",
            " - 2s - loss: 0.0596 - auc: 0.9675 - val_loss: 0.0661 - val_auc: 0.8673\n",
            "Epoch 14/100\n",
            " - 2s - loss: 0.0578 - auc: 0.9670 - val_loss: 0.0656 - val_auc: 0.8549\n",
            "Epoch 15/100\n",
            " - 2s - loss: 0.0561 - auc: 0.9696 - val_loss: 0.0639 - val_auc: 0.8778\n",
            "Epoch 16/100\n",
            " - 2s - loss: 0.0544 - auc: 0.9697 - val_loss: 0.0635 - val_auc: 0.8575\n",
            "Epoch 17/100\n",
            " - 2s - loss: 0.0531 - auc: 0.9708 - val_loss: 0.0615 - val_auc: 0.8842\n",
            "Epoch 18/100\n",
            " - 2s - loss: 0.0519 - auc: 0.9720 - val_loss: 0.0605 - val_auc: 0.8849\n",
            "Epoch 19/100\n",
            " - 2s - loss: 0.0509 - auc: 0.9710 - val_loss: 0.0614 - val_auc: 0.8743\n",
            "Epoch 00019: early stopping\n",
            "0.882584178470355\n",
            "FOLD : 4\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 27s - loss: 0.4776 - auc: 0.7836 - val_loss: 0.2032 - val_auc: 0.8529\n",
            "Epoch 2/100\n",
            " - 2s - loss: 0.1768 - auc: 0.9141 - val_loss: 0.1343 - val_auc: 0.8557\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1287 - auc: 0.9388 - val_loss: 0.1132 - val_auc: 0.8711\n",
            "Epoch 4/100\n",
            " - 2s - loss: 0.1076 - auc: 0.9476 - val_loss: 0.1022 - val_auc: 0.8662\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0950 - auc: 0.9552 - val_loss: 0.0923 - val_auc: 0.8837\n",
            "Epoch 6/100\n",
            " - 2s - loss: 0.0862 - auc: 0.9571 - val_loss: 0.0849 - val_auc: 0.8913\n",
            "Epoch 7/100\n",
            " - 2s - loss: 0.0798 - auc: 0.9600 - val_loss: 0.0820 - val_auc: 0.8673\n",
            "Epoch 8/100\n",
            " - 2s - loss: 0.0747 - auc: 0.9612 - val_loss: 0.0764 - val_auc: 0.8868\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0705 - auc: 0.9645 - val_loss: 0.0751 - val_auc: 0.8859\n",
            "Epoch 10/100\n",
            " - 2s - loss: 0.0671 - auc: 0.9653 - val_loss: 0.0714 - val_auc: 0.8846\n",
            "Epoch 11/100\n",
            " - 3s - loss: 0.0642 - auc: 0.9672 - val_loss: 0.0678 - val_auc: 0.8939\n",
            "Epoch 12/100\n",
            " - 2s - loss: 0.0617 - auc: 0.9665 - val_loss: 0.0675 - val_auc: 0.8758\n",
            "Epoch 13/100\n",
            " - 2s - loss: 0.0595 - auc: 0.9696 - val_loss: 0.0649 - val_auc: 0.8842\n",
            "Epoch 14/100\n",
            " - 2s - loss: 0.0576 - auc: 0.9705 - val_loss: 0.0632 - val_auc: 0.8782\n",
            "Epoch 15/100\n",
            " - 2s - loss: 0.0559 - auc: 0.9712 - val_loss: 0.0627 - val_auc: 0.8803\n",
            "Epoch 16/100\n",
            " - 2s - loss: 0.0543 - auc: 0.9709 - val_loss: 0.0613 - val_auc: 0.8803\n",
            "Epoch 17/100\n",
            " - 2s - loss: 0.0530 - auc: 0.9717 - val_loss: 0.0590 - val_auc: 0.8782\n",
            "Epoch 18/100\n",
            " - 2s - loss: 0.0517 - auc: 0.9735 - val_loss: 0.0600 - val_auc: 0.8731\n",
            "Epoch 00018: early stopping\n",
            "0.8821377908576993\n",
            "FOLD : 5\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 27s - loss: 0.4811 - auc: 0.7885 - val_loss: 0.2101 - val_auc: 0.8278\n",
            "Epoch 2/100\n",
            " - 2s - loss: 0.1768 - auc: 0.9120 - val_loss: 0.1336 - val_auc: 0.8977\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1287 - auc: 0.9375 - val_loss: 0.1100 - val_auc: 0.9235\n",
            "Epoch 4/100\n",
            " - 2s - loss: 0.1079 - auc: 0.9489 - val_loss: 0.1000 - val_auc: 0.9166\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0952 - auc: 0.9526 - val_loss: 0.0913 - val_auc: 0.9099\n",
            "Epoch 6/100\n",
            " - 2s - loss: 0.0864 - auc: 0.9563 - val_loss: 0.0847 - val_auc: 0.9106\n",
            "Epoch 7/100\n",
            " - 2s - loss: 0.0798 - auc: 0.9640 - val_loss: 0.0806 - val_auc: 0.9104\n",
            "Epoch 8/100\n",
            " - 2s - loss: 0.0748 - auc: 0.9611 - val_loss: 0.0760 - val_auc: 0.9263\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0707 - auc: 0.9624 - val_loss: 0.0726 - val_auc: 0.9149\n",
            "Epoch 10/100\n",
            " - 2s - loss: 0.0672 - auc: 0.9649 - val_loss: 0.0692 - val_auc: 0.9294\n",
            "Epoch 11/100\n",
            " - 2s - loss: 0.0643 - auc: 0.9651 - val_loss: 0.0681 - val_auc: 0.9211\n",
            "Epoch 12/100\n",
            " - 2s - loss: 0.0617 - auc: 0.9682 - val_loss: 0.0653 - val_auc: 0.9237\n",
            "Epoch 13/100\n",
            " - 2s - loss: 0.0595 - auc: 0.9696 - val_loss: 0.0640 - val_auc: 0.9221\n",
            "Epoch 14/100\n",
            " - 2s - loss: 0.0575 - auc: 0.9715 - val_loss: 0.0621 - val_auc: 0.9219\n",
            "Epoch 15/100\n",
            " - 2s - loss: 0.0558 - auc: 0.9729 - val_loss: 0.0612 - val_auc: 0.9150\n",
            "Epoch 16/100\n",
            " - 2s - loss: 0.0542 - auc: 0.9736 - val_loss: 0.0613 - val_auc: 0.9103\n",
            "Epoch 00016: early stopping\n",
            "0.9028357081860078\n",
            "FOLD : 6\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 28s - loss: 0.4807 - auc: 0.7681 - val_loss: 0.2038 - val_auc: 0.8354\n",
            "Epoch 2/100\n",
            " - 3s - loss: 0.1766 - auc: 0.9069 - val_loss: 0.1342 - val_auc: 0.9130\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1289 - auc: 0.9317 - val_loss: 0.1104 - val_auc: 0.9084\n",
            "Epoch 4/100\n",
            " - 3s - loss: 0.1081 - auc: 0.9472 - val_loss: 0.0965 - val_auc: 0.9002\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0954 - auc: 0.9502 - val_loss: 0.0887 - val_auc: 0.8895\n",
            "Epoch 6/100\n",
            " - 3s - loss: 0.0865 - auc: 0.9541 - val_loss: 0.0840 - val_auc: 0.9075\n",
            "Epoch 7/100\n",
            " - 3s - loss: 0.0798 - auc: 0.9607 - val_loss: 0.0796 - val_auc: 0.9077\n",
            "Epoch 8/100\n",
            " - 3s - loss: 0.0746 - auc: 0.9623 - val_loss: 0.0763 - val_auc: 0.8938\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0705 - auc: 0.9626 - val_loss: 0.0730 - val_auc: 0.8980\n",
            "Epoch 10/100\n",
            " - 2s - loss: 0.0670 - auc: 0.9671 - val_loss: 0.0702 - val_auc: 0.9030\n",
            "Epoch 11/100\n",
            " - 3s - loss: 0.0640 - auc: 0.9664 - val_loss: 0.0684 - val_auc: 0.9050\n",
            "Epoch 12/100\n",
            " - 2s - loss: 0.0613 - auc: 0.9703 - val_loss: 0.0665 - val_auc: 0.9062\n",
            "Epoch 13/100\n",
            " - 2s - loss: 0.0592 - auc: 0.9707 - val_loss: 0.0642 - val_auc: 0.9036\n",
            "Epoch 14/100\n",
            " - 2s - loss: 0.0572 - auc: 0.9720 - val_loss: 0.0631 - val_auc: 0.8937\n",
            "Epoch 15/100\n",
            " - 2s - loss: 0.0555 - auc: 0.9739 - val_loss: 0.0621 - val_auc: 0.8882\n",
            "Epoch 16/100\n",
            " - 3s - loss: 0.0539 - auc: 0.9718 - val_loss: 0.0611 - val_auc: 0.8913\n",
            "Epoch 17/100\n",
            " - 2s - loss: 0.0523 - auc: 0.9745 - val_loss: 0.0611 - val_auc: 0.8835\n",
            "Epoch 18/100\n",
            " - 2s - loss: 0.0510 - auc: 0.9755 - val_loss: 0.0586 - val_auc: 0.8817\n",
            "Epoch 19/100\n",
            " - 2s - loss: 0.0500 - auc: 0.9759 - val_loss: 0.0584 - val_auc: 0.8889\n",
            "Epoch 20/100\n",
            " - 2s - loss: 0.0488 - auc: 0.9737 - val_loss: 0.0578 - val_auc: 0.8735\n",
            "Epoch 21/100\n",
            " - 3s - loss: 0.0478 - auc: 0.9780 - val_loss: 0.0565 - val_auc: 0.8797\n",
            "Epoch 22/100\n",
            " - 2s - loss: 0.0469 - auc: 0.9790 - val_loss: 0.0569 - val_auc: 0.8811\n",
            "Epoch 00022: early stopping\n",
            "0.9021705377118134\n",
            "FOLD : 7\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 29s - loss: 0.4838 - auc: 0.7775 - val_loss: 0.1999 - val_auc: 0.8558\n",
            "Epoch 2/100\n",
            " - 3s - loss: 0.1782 - auc: 0.9082 - val_loss: 0.1365 - val_auc: 0.9290\n",
            "Epoch 3/100\n",
            " - 3s - loss: 0.1291 - auc: 0.9371 - val_loss: 0.1157 - val_auc: 0.9233\n",
            "Epoch 4/100\n",
            " - 3s - loss: 0.1083 - auc: 0.9427 - val_loss: 0.0987 - val_auc: 0.9299\n",
            "Epoch 5/100\n",
            " - 2s - loss: 0.0955 - auc: 0.9481 - val_loss: 0.0903 - val_auc: 0.9360\n",
            "Epoch 6/100\n",
            " - 3s - loss: 0.0867 - auc: 0.9543 - val_loss: 0.0838 - val_auc: 0.9319\n",
            "Epoch 7/100\n",
            " - 3s - loss: 0.0802 - auc: 0.9552 - val_loss: 0.0786 - val_auc: 0.9285\n",
            "Epoch 8/100\n",
            " - 3s - loss: 0.0750 - auc: 0.9603 - val_loss: 0.0757 - val_auc: 0.9354\n",
            "Epoch 9/100\n",
            " - 2s - loss: 0.0708 - auc: 0.9648 - val_loss: 0.0720 - val_auc: 0.9329\n",
            "Epoch 10/100\n",
            " - 2s - loss: 0.0673 - auc: 0.9656 - val_loss: 0.0694 - val_auc: 0.9302\n",
            "Epoch 11/100\n",
            " - 3s - loss: 0.0644 - auc: 0.9684 - val_loss: 0.0673 - val_auc: 0.9354\n",
            "Epoch 12/100\n",
            " - 3s - loss: 0.0620 - auc: 0.9680 - val_loss: 0.0648 - val_auc: 0.9281\n",
            "Epoch 13/100\n",
            " - 3s - loss: 0.0596 - auc: 0.9703 - val_loss: 0.0635 - val_auc: 0.9312\n",
            "Epoch 14/100\n",
            " - 3s - loss: 0.0577 - auc: 0.9707 - val_loss: 0.0622 - val_auc: 0.9318\n",
            "Epoch 15/100\n",
            " - 3s - loss: 0.0560 - auc: 0.9728 - val_loss: 0.0605 - val_auc: 0.9298\n",
            "Epoch 16/100\n",
            " - 3s - loss: 0.0543 - auc: 0.9738 - val_loss: 0.0592 - val_auc: 0.9205\n",
            "Epoch 17/100\n",
            " - 3s - loss: 0.0530 - auc: 0.9724 - val_loss: 0.0584 - val_auc: 0.9284\n",
            "Epoch 18/100\n",
            " - 3s - loss: 0.0516 - auc: 0.9750 - val_loss: 0.0576 - val_auc: 0.9323\n",
            "Epoch 19/100\n",
            " - 3s - loss: 0.0504 - auc: 0.9735 - val_loss: 0.0558 - val_auc: 0.9296\n",
            "Epoch 20/100\n",
            " - 3s - loss: 0.0494 - auc: 0.9757 - val_loss: 0.0554 - val_auc: 0.9224\n",
            "Epoch 21/100\n",
            " - 3s - loss: 0.0485 - auc: 0.9752 - val_loss: 0.0552 - val_auc: 0.9207\n",
            "Epoch 22/100\n",
            " - 3s - loss: 0.0475 - auc: 0.9757 - val_loss: 0.0553 - val_auc: 0.9231\n",
            "Epoch 00022: early stopping\n",
            "0.9151528304150522\n",
            "FOLD : 8\n",
            "Train on 70532 samples, validate on 7837 samples\n",
            "Epoch 1/100\n",
            " - 30s - loss: 0.4828 - auc: 0.7725 - val_loss: 0.2072 - val_auc: 0.8460\n",
            "Epoch 2/100\n",
            " - 3s - loss: 0.1790 - auc: 0.9140 - val_loss: 0.1358 - val_auc: 0.8876\n",
            "Epoch 3/100\n",
            " - 2s - loss: 0.1298 - auc: 0.9374 - val_loss: 0.1125 - val_auc: 0.8779\n",
            "Epoch 4/100\n",
            " - 2s - loss: 0.1084 - auc: 0.9450 - val_loss: 0.1005 - val_auc: 0.8772\n",
            "Epoch 5/100\n",
            " - 3s - loss: 0.0954 - auc: 0.9485 - val_loss: 0.0922 - val_auc: 0.8686\n",
            "Epoch 6/100\n",
            " - 2s - loss: 0.0865 - auc: 0.9561 - val_loss: 0.0848 - val_auc: 0.8435\n",
            "Epoch 7/100\n",
            " - 2s - loss: 0.0797 - auc: 0.9623 - val_loss: 0.0807 - val_auc: 0.8621\n",
            "Epoch 8/100\n",
            " - 3s - loss: 0.0744 - auc: 0.9623 - val_loss: 0.0761 - val_auc: 0.8555\n",
            "Epoch 9/100\n",
            " - 3s - loss: 0.0703 - auc: 0.9638 - val_loss: 0.0731 - val_auc: 0.8499\n",
            "Epoch 10/100\n",
            " - 3s - loss: 0.0668 - auc: 0.9660 - val_loss: 0.0691 - val_auc: 0.8699\n",
            "Epoch 11/100\n",
            " - 3s - loss: 0.0639 - auc: 0.9675 - val_loss: 0.0667 - val_auc: 0.8534\n",
            "Epoch 12/100\n",
            " - 3s - loss: 0.0613 - auc: 0.9707 - val_loss: 0.0660 - val_auc: 0.8403\n",
            "Epoch 13/100\n",
            " - 3s - loss: 0.0591 - auc: 0.9682 - val_loss: 0.0641 - val_auc: 0.8588\n",
            "Epoch 14/100\n",
            " - 3s - loss: 0.0570 - auc: 0.9704 - val_loss: 0.0621 - val_auc: 0.8395\n",
            "Epoch 15/100\n",
            " - 3s - loss: 0.0553 - auc: 0.9721 - val_loss: 0.0617 - val_auc: 0.8560\n",
            "Epoch 16/100\n",
            " - 3s - loss: 0.0539 - auc: 0.9723 - val_loss: 0.0606 - val_auc: 0.8408\n",
            "Epoch 17/100\n",
            " - 3s - loss: 0.0521 - auc: 0.9752 - val_loss: 0.0589 - val_auc: 0.8583\n",
            "Epoch 18/100\n",
            " - 3s - loss: 0.0510 - auc: 0.9736 - val_loss: 0.0579 - val_auc: 0.8431\n",
            "Epoch 19/100\n",
            " - 3s - loss: 0.0499 - auc: 0.9739 - val_loss: 0.0567 - val_auc: 0.8579\n",
            "Epoch 20/100\n",
            " - 3s - loss: 0.0488 - auc: 0.9759 - val_loss: 0.0567 - val_auc: 0.8515\n",
            "Epoch 21/100\n",
            " - 3s - loss: 0.0478 - auc: 0.9772 - val_loss: 0.0563 - val_auc: 0.8311\n",
            "Epoch 22/100\n",
            " - 3s - loss: 0.0468 - auc: 0.9757 - val_loss: 0.0572 - val_auc: 0.8492\n",
            "Epoch 00022: early stopping\n",
            "0.8527688382630052\n",
            "FOLD : 9\n",
            "Train on 70533 samples, validate on 7836 samples\n",
            "Epoch 1/100\n",
            " - 31s - loss: 0.4743 - auc: 0.7582 - val_loss: 0.2057 - val_auc: 0.8611\n",
            "Epoch 2/100\n",
            " - 3s - loss: 0.1778 - auc: 0.9001 - val_loss: 0.1363 - val_auc: 0.8815\n",
            "Epoch 3/100\n",
            " - 3s - loss: 0.1292 - auc: 0.9298 - val_loss: 0.1094 - val_auc: 0.9062\n",
            "Epoch 4/100\n",
            " - 3s - loss: 0.1081 - auc: 0.9489 - val_loss: 0.0973 - val_auc: 0.9162\n",
            "Epoch 5/100\n",
            " - 3s - loss: 0.0952 - auc: 0.9550 - val_loss: 0.0903 - val_auc: 0.9107\n",
            "Epoch 6/100\n",
            " - 3s - loss: 0.0863 - auc: 0.9543 - val_loss: 0.0840 - val_auc: 0.9140\n",
            "Epoch 7/100\n",
            " - 3s - loss: 0.0797 - auc: 0.9593 - val_loss: 0.0799 - val_auc: 0.9204\n",
            "Epoch 8/100\n",
            " - 3s - loss: 0.0744 - auc: 0.9624 - val_loss: 0.0756 - val_auc: 0.9113\n",
            "Epoch 9/100\n",
            " - 3s - loss: 0.0701 - auc: 0.9681 - val_loss: 0.0735 - val_auc: 0.9127\n",
            "Epoch 10/100\n",
            " - 3s - loss: 0.0665 - auc: 0.9684 - val_loss: 0.0690 - val_auc: 0.9278\n",
            "Epoch 11/100\n",
            " - 3s - loss: 0.0634 - auc: 0.9702 - val_loss: 0.0674 - val_auc: 0.9181\n",
            "Epoch 12/100\n",
            " - 3s - loss: 0.0607 - auc: 0.9718 - val_loss: 0.0665 - val_auc: 0.9109\n",
            "Epoch 13/100\n",
            " - 3s - loss: 0.0585 - auc: 0.9736 - val_loss: 0.0646 - val_auc: 0.9157\n",
            "Epoch 14/100\n",
            " - 3s - loss: 0.0564 - auc: 0.9740 - val_loss: 0.0625 - val_auc: 0.9204\n",
            "Epoch 15/100\n",
            " - 3s - loss: 0.0546 - auc: 0.9759 - val_loss: 0.0611 - val_auc: 0.9177\n",
            "Epoch 16/100\n",
            " - 3s - loss: 0.0531 - auc: 0.9755 - val_loss: 0.0600 - val_auc: 0.9124\n",
            "Epoch 17/100\n",
            " - 3s - loss: 0.0514 - auc: 0.9781 - val_loss: 0.0589 - val_auc: 0.8925\n",
            "Epoch 18/100\n",
            " - 3s - loss: 0.0502 - auc: 0.9764 - val_loss: 0.0580 - val_auc: 0.9215\n",
            "Epoch 19/100\n",
            " - 3s - loss: 0.0489 - auc: 0.9781 - val_loss: 0.0582 - val_auc: 0.9072\n",
            "Epoch 00019: early stopping\n",
            "0.9164457395958556\n",
            "[0.9029980309542461, 0.8694854368246843, 0.9226108558644392, 0.882584178470355, 0.8821377908576993, 0.9028357081860078, 0.9021705377118134, 0.9151528304150522, 0.8527688382630052, 0.9164457395958556]\n",
            "CV : 0.8949189947143159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0VIDmGjCSIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer1.to_csv(f'/content/drive/My Drive/amExprt/{name}.csv', index = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogB6WmmLLQyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}